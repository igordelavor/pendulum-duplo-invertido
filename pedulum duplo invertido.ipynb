{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/igor/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Gym: 0.17.1\n",
      "Tensorflow: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from collections import deque\n",
    "print(\"Gym:\", gym.__version__)\n",
    "print(\"Tensorflow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q network é um algoritmo de aprendizado de máquina do tipo reinforcement learning no qual um agente é \n",
    "#treinado através de uma função de recompensa para chegar ao resultado desejado\n",
    "#no caso da Q network essa função é Q(St,At) = r(t+1) + D*max(Q(S(t+1)))\n",
    "#no qual r(t+1) é a recompensa calculada pelo algoritmo para a próxima ação At no estado St\n",
    "#D é o discount rate, para tomar em consideração a incerteza da recompensa dos cálculos posteriores \n",
    "#ao seguinte passo\n",
    "\n",
    "class QNetwork():\n",
    "    def __init__(self, state_dim, action_size, tau=0.01):\n",
    "        tf.reset_default_graph() #como os nomes das variáveis estão sendo separadas em local e target é boa prática resetar o tensorflow depois cada iteração\n",
    "        self.state_in = tf.placeholder(tf.float32, shape=[None, *state_dim]) #parametros de inicialização da classe\n",
    "        self.action_in = tf.placeholder(tf.int32, shape=[None]) #placeholder para as variáveis que vâo ser alimentadas por valores\n",
    "        self.q_target_in = tf.placeholder(tf.float32, shape=[None]) #são os inputs da rede neural\n",
    "        self.importance_in = tf.placeholder(tf.float32, shape=[None])\n",
    "        action_one_hot = tf.one_hot(self.action_in, depth=action_size)\n",
    "        \n",
    "        self.q_state_local = self.build_model(action_size, \"local\") #cria a versão local da nossa Q network\n",
    "        self.q_state_target = self.build_model(action_size, \"target\") #cria a versão target da nossa Q nextwor\n",
    "        \n",
    "        self.q_state_action = tf.reduce_sum(tf.multiply(self.q_state_local, action_one_hot), axis=1)#faz a multiplicação dos elementos do atual estado da função Q e da próxima melhor ação possível em um só eixo/vetor para receber o valor da nossa ação e retorna como uma dimensão graças ao reduce_sum()\n",
    "        self.error = self.q_state_action - self.q_target_in #define o erro da operação, o erro é a recompensa gerada por uma ação menos a recompensa que deveria ter sido gerada pela ação de acordo com a nossa função\n",
    "        self.loss = tf.reduce_mean(tf.multiply(tf.square(self.error), self.importance_in)) #a perca do algoritmo é igual a multiplcação do quadrado do erro com \n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(self.loss)\n",
    "        \n",
    "        self.local_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"local\") #separa as variáveis local\n",
    "        self.target_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"target\") #separa as variaveis target\n",
    "        self.updater = tf.group([tf.assign(t, t + tau*(l-t)) for t,l in zip(self.target_vars, self.local_vars)]) #operação de atualização das variáveis na rede target, assign() permite colocar um novo valor de uma variável para cada seção\n",
    "        \n",
    "    def build_model(self, action_size, scope):\n",
    "        with tf.variable_scope(scope):#permite a criação de novas variáveis e valida que essas novas variáveis estão no gráfico default\n",
    "            hidden1 = tf.layers.dense(self.state_in, 100, activation=tf.nn.relu)\n",
    "            q_state = tf.layers.dense(hidden1, action_size, activation=None)\n",
    "            return q_state\n",
    "        \n",
    "    def update_model(self, session, state, action, q_target, importance):\n",
    "        feed = {self.state_in: state, self.action_in: action, self.q_target_in: q_target, self.importance_in: importance}\n",
    "        error, _, _ = session.run([self.error, self.optimizer, self.updater], feed_dict=feed)\n",
    "        return error\n",
    "        \n",
    "    def get_q_state(self, session, state, use_target=False):\n",
    "        q_state_op = self.q_state_target if use_target else self.q_state_local\n",
    "        q_state = session.run(q_state_op, feed_dict={self.state_in: state})\n",
    "        return q_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#o replaybuffer é uma \"função\" que usa todos os \"steps\" e faz um sample deles para ter uma ideia melhor da recompensa da próxima ação\n",
    "#sem o replaybuffer o nosso algoritmo pode ficar muito viçado nas experiências que ocorrem comumente \n",
    "#e não usarem experiências mais raras, diminuindo a capacidade do algoritmo de fazer ações exploratórias\n",
    "class PrioritizedReplayBuffer():\n",
    "    def __init__(self, maxlen):\n",
    "        self.buffer = deque(maxlen=maxlen)\n",
    "        self.priorities = deque(maxlen=maxlen)\n",
    "        \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        self.priorities.append(max(self.priorities, default=1))\n",
    "        \n",
    "    def get_probabilities(self, priority_scale):\n",
    "        scaled_priorities = np.array(self.priorities) ** priority_scale\n",
    "        sample_probabilities = scaled_priorities / sum(scaled_priorities)\n",
    "        return sample_probabilities\n",
    "    \n",
    "    def get_importance(self, probabilities):\n",
    "        importance = 1/len(self.buffer) * 1/probabilities\n",
    "        importance_normalized = importance / max(importance)\n",
    "        return importance_normalized\n",
    "        \n",
    "    def sample(self, batch_size, priority_scale=1.0):\n",
    "        sample_size = min(len(self.buffer), batch_size)\n",
    "        sample_probs = self.get_probabilities(priority_scale)\n",
    "        sample_indices = random.choices(range(len(self.buffer)), k=sample_size, weights=sample_probs)\n",
    "        samples = np.array(self.buffer)[sample_indices]\n",
    "        importance = self.get_importance(sample_probs[sample_indices])\n",
    "        return map(list, zip(*samples)), importance, sample_indices\n",
    "    \n",
    "    def set_priorities(self, indices, errors, offset=0.1):\n",
    "        for i,e in zip(indices, errors):\n",
    "            self.priorities[i] = abs(e) + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uma double q network passa a ação por duas redes neurais para ter uma aproximação da recompensa do próximo passo(next action taken) mais precisa\n",
    "#uma Q network será a rede local e a outra será a target network, a local reflete onde o nosso algoritmo está nesse momento e a target reflete o valor que ela deveria estar no msm momento\n",
    "class DoubleDQNAgent():\n",
    "    def __init__(self, env):\n",
    "        self.state_dim = env.observation_space.shape\n",
    "        self.action_size = env.action_space.n\n",
    "        self.q_network = QNetwork(self.state_dim, self.action_size)\n",
    "        self.replay_buffer = PrioritizedReplayBuffer(maxlen=100000) #permite usar um vetor de comprimento 100000, no qual a experiência do algoritmo está em cada elemento do mais velho pro mais novo, a função deque joga fora as informações mais velhas quando o vetor estiver cheio\n",
    "        self.gamma = 0.97\n",
    "        self.eps = 1.0 #variável que corresponde à probabilidade do algoritmo escolher uma ação exploratória(ação que pode gerar maior recompensa no futuro, após N+1 espaços de estado) ao invés de uma ação gananciosa(a que irá gerar a maior recompensa possível no próxmo passo)\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        q_state = self.q_network.get_q_state(self.sess, [state])\n",
    "        action_greedy = np.argmax(q_state)#retorna os máximos valores de recompensa da função Q para ter a greedy action\n",
    "        action_random = np.random.randint(self.action_size) #ação aleatória\n",
    "        action = action_random if random.random() < self.eps else action_greedy #define a probabilidade de selecionar a ação greedy/aleatória baseado no valor de epsilon\n",
    "        return action\n",
    "    \n",
    "    def get_env_action(self, action):\n",
    "        return action\n",
    "    \n",
    "    def train(self, state, action, next_state, reward, done, use_DDQN=True, a=0.0): #função que irá treinar os novos valores de Q, puxando esses valores para o nosso replaybuffer\n",
    "        self.replay_buffer.add((state, action, next_state, reward, done))\n",
    "        (states, actions, next_states, rewards, dones), importance, indices = self.replay_buffer.sample(50, priority_scale=a)\n",
    "        \n",
    "        next_actions = np.argmax(self.q_network.get_q_state(self.sess, next_states, use_target=False), axis=1)\n",
    "        q_next_states = self.q_network.get_q_state(self.sess, next_states, use_target=use_DDQN)\n",
    "        q_next_states[dones] = np.zeros([self.action_size]) #enche a matriz dos proximos estados de zero conforme o action_size\n",
    "        q_next_states_next_actions = q_next_states[np.arange(next_actions.shape[0]), next_actions]\n",
    "        q_targets = rewards + self.gamma * q_next_states_next_actions #função Q, isso é Q = r(t)+D*Q(S(t+1))\n",
    "        errors = self.q_network.update_model(self.sess, states, actions, q_targets, importance**(1-self.eps))\n",
    "        \n",
    "        self.replay_buffer.set_priorities(indices, errors)\n",
    "        \n",
    "        if done: self.eps = max(0.1, 0.98*self.eps)\n",
    "    \n",
    "    def __del__(self): #é o \"destructor\", sempre que inicializamos uma sessão no tensorflow é recomendado fechar essa sessão quando pararmos de utilizá-lo\n",
    "        self.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretiza o tipo de ação do agente para utilizar ambientes que usam espaços contínuos\n",
    "#se a ação do ambiente n for discreta ele não faz nada\n",
    "class DiscretizedDQNAgent(DoubleDQNAgent):\n",
    "    def __init__(self, env, n_actions=10):\n",
    "        self.is_discrete = type(env.action_space) == gym.spaces.discrete.Discrete #se for discreto retorna como uma espaço de estados discreto\n",
    "        if not self.is_discrete:\n",
    "            env.action_space.n = n_actions #se n for discreto retorna as ações em espaços de estados e o numpy.linspace() coloca uma posição para cada ação\n",
    "            self.actions = np.linspace(env.action_space.low, env.action_space.high, n_actions)\n",
    "        super().__init__(env)\n",
    "        \n",
    "    def get_env_action(self, action):\n",
    "        if not self.is_discrete:\n",
    "            action = [self.actions[action]]\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box(11,)\n",
      "Action space: Box(1,)\n"
     ]
    }
   ],
   "source": [
    "from gym import wrappers\n",
    "from time import time\n",
    "env_names = [\"CartPole-v0\",\n",
    "             \"MountainCar-v0\",\n",
    "             \"MountainCarContinuous-v0\",\n",
    "             \"Pendulum-v0\",\n",
    "             \"Acrobot-v1\",\n",
    "             \"InvertedDoublePendulum-v2\"]\n",
    "env = gym.make(env_names[5])\n",
    "env = wrappers.Monitor(env, './videos/' + str(time()) + '/')\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "WARNING:tensorflow:From <ipython-input-2-e7c3a4ea4893>:31: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/igor/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "Creating window glfw\n",
      "Episode: 0, total_reward: 54.13\n",
      "Episode: 1, total_reward: 54.77\n",
      "Episode: 2, total_reward: 35.68\n",
      "Episode: 3, total_reward: 63.70\n",
      "Episode: 4, total_reward: 36.23\n",
      "Episode: 5, total_reward: 53.91\n",
      "Episode: 6, total_reward: 101.04\n",
      "Episode: 7, total_reward: 36.13\n",
      "Episode: 8, total_reward: 54.08\n",
      "Episode: 9, total_reward: 73.36\n",
      "Episode: 10, total_reward: 45.47\n",
      "Episode: 11, total_reward: 44.92\n",
      "Episode: 12, total_reward: 36.22\n",
      "Episode: 13, total_reward: 44.90\n",
      "Episode: 14, total_reward: 45.07\n",
      "Episode: 15, total_reward: 44.85\n",
      "Episode: 16, total_reward: 54.41\n",
      "Episode: 17, total_reward: 54.50\n",
      "Episode: 18, total_reward: 36.23\n",
      "Episode: 19, total_reward: 54.48\n",
      "Episode: 20, total_reward: 35.97\n",
      "Episode: 21, total_reward: 54.85\n",
      "Episode: 22, total_reward: 73.13\n",
      "Episode: 23, total_reward: 45.63\n",
      "Episode: 24, total_reward: 82.47\n",
      "Episode: 25, total_reward: 45.43\n",
      "Episode: 26, total_reward: 35.67\n",
      "Episode: 27, total_reward: 26.74\n",
      "Episode: 28, total_reward: 36.11\n",
      "Episode: 29, total_reward: 45.19\n",
      "Episode: 30, total_reward: 36.19\n",
      "Episode: 31, total_reward: 45.03\n",
      "Episode: 32, total_reward: 44.81\n",
      "Episode: 33, total_reward: 36.12\n",
      "Episode: 34, total_reward: 45.33\n",
      "Episode: 35, total_reward: 35.92\n",
      "Episode: 36, total_reward: 35.99\n",
      "Episode: 37, total_reward: 36.06\n",
      "Episode: 38, total_reward: 45.32\n",
      "Episode: 39, total_reward: 54.29\n",
      "Episode: 40, total_reward: 35.76\n",
      "Episode: 41, total_reward: 36.17\n",
      "Episode: 42, total_reward: 54.41\n",
      "Episode: 43, total_reward: 36.12\n",
      "Episode: 44, total_reward: 36.01\n",
      "Episode: 45, total_reward: 100.91\n",
      "Episode: 46, total_reward: 63.55\n",
      "Episode: 47, total_reward: 35.93\n",
      "Episode: 48, total_reward: 63.59\n",
      "Episode: 49, total_reward: 35.99\n",
      "Episode: 50, total_reward: 35.70\n",
      "Episode: 51, total_reward: 45.11\n",
      "Episode: 52, total_reward: 36.28\n",
      "Episode: 53, total_reward: 64.17\n",
      "Episode: 54, total_reward: 36.30\n",
      "Episode: 55, total_reward: 54.62\n",
      "Episode: 56, total_reward: 73.17\n",
      "Episode: 57, total_reward: 36.05\n",
      "Episode: 58, total_reward: 45.19\n",
      "Episode: 59, total_reward: 44.88\n",
      "Episode: 60, total_reward: 45.41\n",
      "Episode: 61, total_reward: 92.09\n",
      "Episode: 62, total_reward: 44.72\n",
      "Episode: 63, total_reward: 36.01\n",
      "Episode: 64, total_reward: 36.03\n",
      "Episode: 65, total_reward: 35.96\n",
      "Episode: 66, total_reward: 73.55\n",
      "Episode: 67, total_reward: 54.49\n",
      "Episode: 68, total_reward: 36.09\n",
      "Episode: 69, total_reward: 36.18\n",
      "Episode: 70, total_reward: 44.81\n",
      "Episode: 71, total_reward: 35.68\n",
      "Episode: 72, total_reward: 35.99\n",
      "Episode: 73, total_reward: 36.01\n",
      "Episode: 74, total_reward: 36.06\n",
      "Episode: 75, total_reward: 35.86\n",
      "Episode: 76, total_reward: 63.71\n",
      "Episode: 77, total_reward: 36.14\n",
      "Episode: 78, total_reward: 35.54\n",
      "Episode: 79, total_reward: 35.97\n",
      "Episode: 80, total_reward: 36.03\n",
      "Episode: 81, total_reward: 26.87\n",
      "Episode: 82, total_reward: 35.49\n",
      "Episode: 83, total_reward: 35.29\n",
      "Episode: 84, total_reward: 36.00\n",
      "Episode: 85, total_reward: 35.65\n",
      "Episode: 86, total_reward: 35.70\n",
      "Episode: 87, total_reward: 35.49\n",
      "Episode: 88, total_reward: 35.48\n",
      "Episode: 89, total_reward: 35.42\n",
      "Episode: 90, total_reward: 35.90\n",
      "Episode: 91, total_reward: 35.52\n",
      "Episode: 92, total_reward: 45.41\n",
      "Episode: 93, total_reward: 26.89\n",
      "Episode: 94, total_reward: 45.49\n",
      "Episode: 95, total_reward: 35.69\n",
      "Episode: 96, total_reward: 26.78\n",
      "Episode: 97, total_reward: 45.50\n",
      "Episode: 98, total_reward: 26.86\n",
      "Episode: 99, total_reward: 35.95\n",
      "Episode: 100, total_reward: 26.78\n",
      "Episode: 101, total_reward: 26.83\n",
      "Episode: 102, total_reward: 26.77\n",
      "Episode: 103, total_reward: 45.16\n",
      "Episode: 104, total_reward: 36.03\n",
      "Episode: 105, total_reward: 36.09\n",
      "Episode: 106, total_reward: 35.65\n",
      "Episode: 107, total_reward: 73.19\n",
      "Episode: 108, total_reward: 54.64\n",
      "Episode: 109, total_reward: 44.84\n",
      "Episode: 110, total_reward: 35.95\n",
      "Episode: 111, total_reward: 35.98\n",
      "Episode: 112, total_reward: 36.02\n",
      "Episode: 113, total_reward: 54.44\n",
      "Episode: 114, total_reward: 45.25\n",
      "Episode: 115, total_reward: 45.32\n",
      "Episode: 116, total_reward: 35.88\n",
      "Episode: 117, total_reward: 45.27\n",
      "Episode: 118, total_reward: 54.33\n",
      "Episode: 119, total_reward: 45.34\n",
      "Episode: 120, total_reward: 45.56\n",
      "Episode: 121, total_reward: 54.67\n",
      "Episode: 122, total_reward: 45.40\n",
      "Episode: 123, total_reward: 54.00\n",
      "Episode: 124, total_reward: 35.48\n",
      "Episode: 125, total_reward: 44.76\n",
      "Episode: 126, total_reward: 54.38\n",
      "Episode: 127, total_reward: 63.54\n",
      "Episode: 128, total_reward: 63.44\n",
      "Episode: 129, total_reward: 35.32\n",
      "Episode: 130, total_reward: 54.80\n",
      "Episode: 131, total_reward: 54.58\n",
      "Episode: 132, total_reward: 72.91\n",
      "Episode: 133, total_reward: 35.49\n",
      "Episode: 134, total_reward: 44.82\n",
      "Episode: 135, total_reward: 35.76\n",
      "Episode: 136, total_reward: 36.11\n",
      "Episode: 137, total_reward: 35.81\n",
      "Episode: 138, total_reward: 36.17\n",
      "Episode: 139, total_reward: 35.78\n",
      "Episode: 140, total_reward: 35.59\n",
      "Episode: 141, total_reward: 45.05\n",
      "Episode: 142, total_reward: 35.69\n",
      "Episode: 143, total_reward: 35.61\n",
      "Episode: 144, total_reward: 35.69\n",
      "Episode: 145, total_reward: 35.47\n",
      "Episode: 146, total_reward: 35.57\n",
      "Episode: 147, total_reward: 35.66\n",
      "Episode: 148, total_reward: 35.46\n",
      "Episode: 149, total_reward: 35.48\n",
      "Episode: 150, total_reward: 35.45\n",
      "Episode: 151, total_reward: 45.11\n",
      "Episode: 152, total_reward: 35.79\n",
      "Episode: 153, total_reward: 35.37\n",
      "Episode: 154, total_reward: 35.73\n",
      "Episode: 155, total_reward: 35.76\n",
      "Episode: 156, total_reward: 35.68\n",
      "Episode: 157, total_reward: 35.56\n",
      "Episode: 158, total_reward: 35.64\n",
      "Episode: 159, total_reward: 26.93\n",
      "Episode: 160, total_reward: 36.29\n",
      "Episode: 161, total_reward: 35.52\n",
      "Episode: 162, total_reward: 35.45\n",
      "Episode: 163, total_reward: 45.21\n",
      "Episode: 164, total_reward: 64.05\n",
      "Episode: 165, total_reward: 27.00\n",
      "Episode: 166, total_reward: 35.62\n",
      "Episode: 167, total_reward: 35.97\n",
      "Episode: 168, total_reward: 35.61\n",
      "Episode: 169, total_reward: 35.51\n",
      "Episode: 170, total_reward: 35.56\n",
      "Episode: 171, total_reward: 36.10\n",
      "Episode: 172, total_reward: 35.75\n",
      "Episode: 173, total_reward: 35.67\n",
      "Episode: 174, total_reward: 35.96\n",
      "Episode: 175, total_reward: 35.88\n",
      "Episode: 176, total_reward: 35.79\n",
      "Episode: 177, total_reward: 35.73\n",
      "Episode: 178, total_reward: 35.96\n",
      "Episode: 179, total_reward: 35.68\n",
      "Episode: 180, total_reward: 54.21\n",
      "Episode: 181, total_reward: 35.49\n",
      "Episode: 182, total_reward: 35.92\n",
      "Episode: 183, total_reward: 35.79\n",
      "Episode: 184, total_reward: 45.20\n",
      "Episode: 185, total_reward: 45.13\n",
      "Episode: 186, total_reward: 26.91\n",
      "Episode: 187, total_reward: 35.72\n",
      "Episode: 188, total_reward: 54.22\n",
      "Episode: 189, total_reward: 120.11\n",
      "Episode: 190, total_reward: 82.77\n",
      "Episode: 191, total_reward: 82.51\n",
      "Episode: 192, total_reward: 101.15\n",
      "Episode: 193, total_reward: 63.36\n",
      "Episode: 194, total_reward: 72.65\n",
      "Episode: 195, total_reward: 119.28\n",
      "Episode: 196, total_reward: 63.47\n",
      "Episode: 197, total_reward: 54.66\n",
      "Episode: 198, total_reward: 73.20\n",
      "Episode: 199, total_reward: 63.80\n",
      "Episode: 200, total_reward: 63.82\n",
      "Episode: 201, total_reward: 54.78\n",
      "Episode: 202, total_reward: 73.29\n",
      "Episode: 203, total_reward: 81.87\n",
      "Episode: 204, total_reward: 110.72\n",
      "Episode: 205, total_reward: 92.21\n",
      "Episode: 206, total_reward: 156.45\n",
      "Episode: 207, total_reward: 91.71\n",
      "Episode: 208, total_reward: 101.48\n",
      "Episode: 209, total_reward: 91.89\n",
      "Episode: 210, total_reward: 92.35\n",
      "Episode: 211, total_reward: 82.95\n",
      "Episode: 212, total_reward: 101.09\n",
      "Episode: 213, total_reward: 82.68\n",
      "Episode: 214, total_reward: 82.85\n",
      "Episode: 215, total_reward: 91.61\n",
      "Episode: 216, total_reward: 92.00\n",
      "Episode: 217, total_reward: 82.63\n",
      "Episode: 218, total_reward: 73.64\n",
      "Episode: 219, total_reward: 138.26\n",
      "Episode: 220, total_reward: 101.23\n",
      "Episode: 221, total_reward: 54.54\n",
      "Episode: 222, total_reward: 110.51\n",
      "Episode: 223, total_reward: 120.23\n",
      "Episode: 224, total_reward: 101.35\n",
      "Episode: 225, total_reward: 110.83\n",
      "Episode: 226, total_reward: 83.07\n",
      "Episode: 227, total_reward: 120.35\n",
      "Episode: 228, total_reward: 91.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 229, total_reward: 44.78\n",
      "Episode: 230, total_reward: 54.44\n",
      "Episode: 231, total_reward: 73.23\n",
      "Episode: 232, total_reward: 91.88\n",
      "Episode: 233, total_reward: 129.57\n",
      "Episode: 234, total_reward: 91.60\n",
      "Episode: 235, total_reward: 119.94\n",
      "Episode: 236, total_reward: 82.58\n",
      "Episode: 237, total_reward: 91.80\n",
      "Episode: 238, total_reward: 101.41\n",
      "Episode: 239, total_reward: 82.78\n",
      "Episode: 240, total_reward: 83.06\n",
      "Episode: 241, total_reward: 128.75\n",
      "Episode: 242, total_reward: 82.23\n",
      "Episode: 243, total_reward: 82.41\n",
      "Episode: 244, total_reward: 139.00\n",
      "Episode: 245, total_reward: 82.58\n",
      "Episode: 246, total_reward: 82.76\n",
      "Episode: 247, total_reward: 82.95\n",
      "Episode: 248, total_reward: 101.44\n",
      "Episode: 249, total_reward: 82.29\n",
      "Episode: 250, total_reward: 54.70\n",
      "Episode: 251, total_reward: 92.01\n",
      "Episode: 252, total_reward: 109.70\n",
      "Episode: 253, total_reward: 73.64\n",
      "Episode: 254, total_reward: 73.21\n",
      "Episode: 255, total_reward: 91.76\n",
      "Episode: 256, total_reward: 119.40\n",
      "Episode: 257, total_reward: 91.69\n",
      "Episode: 258, total_reward: 92.50\n",
      "Episode: 259, total_reward: 110.86\n",
      "Episode: 260, total_reward: 92.25\n",
      "Episode: 261, total_reward: 92.06\n",
      "Episode: 262, total_reward: 92.09\n",
      "Episode: 263, total_reward: 73.62\n",
      "Episode: 264, total_reward: 72.74\n",
      "Episode: 265, total_reward: 82.85\n",
      "Episode: 266, total_reward: 147.54\n",
      "Episode: 267, total_reward: 147.40\n",
      "Episode: 268, total_reward: 101.43\n",
      "Episode: 269, total_reward: 82.64\n",
      "Episode: 270, total_reward: 137.66\n",
      "Episode: 271, total_reward: 119.33\n",
      "Episode: 272, total_reward: 101.24\n",
      "Episode: 273, total_reward: 166.72\n",
      "Episode: 274, total_reward: 185.22\n",
      "Episode: 275, total_reward: 100.84\n",
      "Episode: 276, total_reward: 45.21\n",
      "Episode: 277, total_reward: 73.32\n",
      "Episode: 278, total_reward: 128.03\n",
      "Episode: 279, total_reward: 91.85\n",
      "Episode: 280, total_reward: 138.51\n",
      "Episode: 281, total_reward: 101.37\n",
      "Episode: 282, total_reward: 82.94\n",
      "Episode: 283, total_reward: 54.35\n",
      "Episode: 284, total_reward: 101.58\n",
      "Episode: 285, total_reward: 63.33\n",
      "Episode: 286, total_reward: 44.96\n",
      "Episode: 287, total_reward: 91.93\n",
      "Episode: 288, total_reward: 82.98\n",
      "Episode: 289, total_reward: 119.88\n",
      "Episode: 290, total_reward: 92.05\n",
      "Episode: 291, total_reward: 101.45\n",
      "Episode: 292, total_reward: 91.50\n",
      "Episode: 293, total_reward: 92.34\n",
      "Episode: 294, total_reward: 92.07\n",
      "Episode: 295, total_reward: 54.36\n",
      "Episode: 296, total_reward: 110.71\n",
      "Episode: 297, total_reward: 110.94\n",
      "Episode: 298, total_reward: 91.94\n",
      "Episode: 299, total_reward: 82.94\n",
      "Episode: 300, total_reward: 120.32\n",
      "Episode: 301, total_reward: 111.12\n",
      "Episode: 302, total_reward: 101.43\n",
      "Episode: 303, total_reward: 91.98\n",
      "Episode: 304, total_reward: 138.16\n",
      "Episode: 305, total_reward: 101.50\n",
      "Episode: 306, total_reward: 83.21\n",
      "Episode: 307, total_reward: 147.77\n",
      "Episode: 308, total_reward: 120.17\n",
      "Episode: 309, total_reward: 110.42\n",
      "Episode: 310, total_reward: 137.77\n",
      "Episode: 311, total_reward: 92.05\n",
      "Episode: 312, total_reward: 128.37\n",
      "Episode: 313, total_reward: 110.63\n",
      "Episode: 314, total_reward: 101.04\n",
      "Episode: 315, total_reward: 101.13\n",
      "Episode: 316, total_reward: 137.76\n",
      "Episode: 317, total_reward: 110.54\n",
      "Episode: 318, total_reward: 82.67\n",
      "Episode: 319, total_reward: 82.09\n",
      "Episode: 320, total_reward: 101.22\n",
      "Episode: 321, total_reward: 92.21\n",
      "Episode: 322, total_reward: 101.06\n",
      "Episode: 323, total_reward: 83.20\n",
      "Episode: 324, total_reward: 72.76\n",
      "Episode: 325, total_reward: 101.38\n",
      "Episode: 326, total_reward: 92.17\n",
      "Episode: 327, total_reward: 92.03\n",
      "Episode: 328, total_reward: 120.48\n",
      "Episode: 329, total_reward: 119.75\n",
      "Episode: 330, total_reward: 92.09\n",
      "Episode: 331, total_reward: 129.72\n",
      "Episode: 332, total_reward: 35.94\n",
      "Episode: 333, total_reward: 82.18\n",
      "Episode: 334, total_reward: 92.32\n",
      "Episode: 335, total_reward: 73.02\n",
      "Episode: 336, total_reward: 110.78\n",
      "Episode: 337, total_reward: 63.75\n",
      "Episode: 338, total_reward: 110.45\n",
      "Episode: 339, total_reward: 120.23\n",
      "Episode: 340, total_reward: 73.68\n",
      "Episode: 341, total_reward: 101.32\n",
      "Episode: 342, total_reward: 83.04\n",
      "Episode: 343, total_reward: 148.34\n",
      "Episode: 344, total_reward: 101.66\n",
      "Episode: 345, total_reward: 101.54\n",
      "Episode: 346, total_reward: 101.52\n",
      "Episode: 347, total_reward: 73.34\n",
      "Episode: 348, total_reward: 73.26\n",
      "Episode: 349, total_reward: 92.19\n",
      "Episode: 350, total_reward: 120.19\n",
      "Episode: 351, total_reward: 165.54\n",
      "Episode: 352, total_reward: 82.84\n",
      "Episode: 353, total_reward: 63.95\n",
      "Episode: 354, total_reward: 82.59\n",
      "Episode: 355, total_reward: 92.32\n",
      "Episode: 356, total_reward: 92.13\n",
      "Episode: 357, total_reward: 100.86\n",
      "Episode: 358, total_reward: 63.42\n",
      "Episode: 359, total_reward: 110.57\n",
      "Episode: 360, total_reward: 92.19\n",
      "Episode: 361, total_reward: 44.63\n",
      "Episode: 362, total_reward: 147.94\n",
      "Episode: 363, total_reward: 91.86\n",
      "Episode: 364, total_reward: 91.85\n",
      "Episode: 365, total_reward: 82.93\n",
      "Episode: 366, total_reward: 82.71\n",
      "Episode: 367, total_reward: 92.05\n",
      "Episode: 368, total_reward: 45.09\n",
      "Episode: 369, total_reward: 82.34\n",
      "Episode: 370, total_reward: 148.25\n",
      "Episode: 371, total_reward: 83.00\n",
      "Episode: 372, total_reward: 82.31\n",
      "Episode: 373, total_reward: 63.94\n",
      "Episode: 374, total_reward: 91.98\n",
      "Episode: 375, total_reward: 91.66\n",
      "Episode: 376, total_reward: 101.06\n",
      "Episode: 377, total_reward: 73.39\n",
      "Episode: 378, total_reward: 92.07\n",
      "Episode: 379, total_reward: 110.16\n",
      "Episode: 380, total_reward: 100.96\n",
      "Episode: 381, total_reward: 101.66\n",
      "Episode: 382, total_reward: 120.30\n",
      "Episode: 383, total_reward: 73.60\n",
      "Episode: 384, total_reward: 54.58\n",
      "Episode: 385, total_reward: 101.59\n",
      "Episode: 386, total_reward: 101.22\n",
      "Episode: 387, total_reward: 92.34\n",
      "Episode: 388, total_reward: 110.98\n",
      "Episode: 389, total_reward: 92.20\n",
      "Episode: 390, total_reward: 91.20\n",
      "Episode: 391, total_reward: 148.05\n",
      "Episode: 392, total_reward: 129.26\n",
      "Episode: 393, total_reward: 63.47\n",
      "Episode: 394, total_reward: 203.57\n",
      "Episode: 395, total_reward: 148.49\n",
      "Episode: 396, total_reward: 82.59\n",
      "Episode: 397, total_reward: 82.59\n",
      "Episode: 398, total_reward: 82.58\n",
      "Episode: 399, total_reward: 92.04\n"
     ]
    }
   ],
   "source": [
    "#sistema de treino do agente e calculo da recompensa\n",
    "num_runs = 1\n",
    "run_rewards = []\n",
    "\n",
    "for n in range(num_runs):\n",
    "    print(\"Run {}\".format(n))\n",
    "    ep_rewards = []\n",
    "    agent = None\n",
    "    agent = DiscretizedDQNAgent(env)\n",
    "    num_episodes = 400\n",
    "\n",
    "    for ep in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, info = env.step(agent.get_env_action(action))\n",
    "            agent.train(state, action, next_state, reward, done, a=0.7)\n",
    "            env.render()\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "        ep_rewards.append(total_reward)\n",
    "        print(\"Episode: {}, total_reward: {:.2f}\".format(ep, total_reward))\n",
    "        \n",
    "    run_rewards.append(ep_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe5320d0cd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for n, ep_rewards in enumerate(run_rewards):\n",
    "    x = range(len(ep_rewards))\n",
    "    cumsum = np.cumsum(ep_rewards) #soma cumulativa das recompensas de cada treino\n",
    "    avgs = [cumsum[ep]/(ep+1) if ep<400 else (cumsum[ep]-cumsum[ep-400])/400 for ep in x]\n",
    "    plt.plot(x, avgs, label=env_names[n])\n",
    "    \n",
    "plt.title(\"5 Environment performance\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Last 400 episode average rewards\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
